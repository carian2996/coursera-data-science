from = levels(factor(cut2(training$Cement, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- mapvalues(cut2(training$FlyAsh, g=4),
from = levels(factor(cut2(training$FlyAsh, g=4))),
to = c("red", "blue", "yellow", "green"))
cut2(training$FlyAsh, g=4)
training$FlyAsh
summary(training)
summary(training)
fcolor <- mapvalues(cut2(training$Age, g=4),
from = levels(factor(cut2(training$Age, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- cut2(training$Age, g=4)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$BlastFurnaceSlag, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, training, geom = "hist")
qplot(Superplasticizer, training, geom = "histogram")
summary(training$Superplasticizer)
hist(training$Superplasticizer)
log(0)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)[substr(names(training), 1, 2) == "IL"]
library(caret)
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProcess(trainingIL, method = "pca", pcaComp = 7)
preProc <- preProcess(trainingIL, method = "pca", pcaComp = 7)
?preProcess
preProc$numComp
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.9)
preProc
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.8)
preProc
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?cblind
newtraining <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
modelFit <- train(newtraining$training$diagnosis ~ ., method = "glm", data = newtraining)
names(newtraining)[13]
names(newtraining)[13] <- "diag"
modelFit <- train(newtraining$diag ~ ., method = "glm", data = newtraining)
modelFitPCA <- train(newtraining$diag ~ ., method = "glm", preProcess = "pca", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = training2)
inTrain = createDataPartition(newtraining$diag, p = 3/4)[[1]]
training2 = newtraining[ inTrain,]
testing2 = newtraining[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
install.packages("e1071")
install.packages("e1071")
install.packages("e1071")
install.packages("~/Downloads/e1071_1.6-4.tar.gz", repos = NULL, type = "source")
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
modelFitPCA <- train(training2$diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
confusionMatrix(modelFit)
predictors
predictorsIL <- predictors[, substr(names(confusionMatrix(modelFit)), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
predictorsIL
predictorsIL <- predictors[, substr(names(predictors), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictions1 <- predict(modelFit, newdata = testing2)
confusionMatrix(modelFit, predictions1)
confusionMatrix(predictions1, testing2)
confusionMatrix(predictions1, testing2$diag)
predictions2 <- predict(modelFitPCA, newdata = testing2)
confusionMatrix(predictions2, testing2$diag)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, p = 0.7, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
set.seed(125)
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
install.packages("rattle")
install.packages("rattle")
library(rattle)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("rpart.plot")
install.packages("rpart.plot")
fancyRpartPlot(CARTmodel$finalModel)
CARTmodel$finalModel
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(olive)
data <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]
data(olive)
olive <- olive[,-1]
data(olive)
all.equal(olive$Region, olive$Area)
equal(olive$Region, olive$Area)
all(olive$Region, olive$Area)
class(olive$Region)
class(olive$Area)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
set.seed(123)
library(pgmm)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- olive[trainIndex, ]
test <- olive[-trainIndex, ]
?train
getModelInfo()
treeModel <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
treeModel$finalModel
fancyRpartPlot(treeModel$finalModel)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fitModel <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
values <- testSA$chd
predictions <- predict(fitModel, testSA)
missClass(values, predictions)
values <- trainSA$chd
predictions <- predict(fitModel, trainSA)
missClass(values, predictions)
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
vowel.train
y <- factor()
train <- cbind(data(vowel.train), y)
train <- cbind(data(vowel.train), as.factor(y))
train <- data(vowel.train)
train <- cbind(train, as.factor(y))
data(vowel.train)
data(vowel.test)
vowel.train
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
?varImp
varImp(rdmforest)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
data$Case
factor(data$Case)
factor(data$Case)
?factor
levels(data$Case)
data$Case == levels(data$Case)[1]
levels(data$Case)[1]
data$Case == levels(data$Case)[2]
levels(data$Case)[2]
trainIndex <- data$Case == levels(data$Case)[2]
training <- data[trainIndex, ]
-trainIndex
?T
c(V, F) == F
c(V, F)
c(T, F) == F
testing <- data[trainIndex == F, ]
set.seed(125)
fitModel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(fitModel$finalModel)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
varImp(rdmforest)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
varImp(rdmforest)
order(varImp(rdmforest))
?order
sort(varImp(rdmforest))
sort(order(varImp(rdmforest)))
order(varImp(rdmforest))
setwd("~/Desktop/repos/datasciencecoursera/Practical Machine Learning/Prediction Assignment")
library(lattice)
library(ggplot2)
library(caret)
library(rattle)
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
train <- train[, -c(1, 2, grep("time", names(train)))]
keep <- colSums(is.na(train)) < 19000
train <- train[, keep]
set.seed(1111)
indexTrain <- createDataPartition(train$classe, p = 0.60, list = F)
trTrain <- train[indexTrain, ]
teTrain <- train[-indexTrain, ]
train_control <- trainControl(method="cv", number=10)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
library(randomForest)
library(lattice)
library(ggplot2)
library(caret)
library(rattle)
library(randomForest)
rfModel2 <- randomForest(classe ~ ., preProcess = "pca", trControl = train_control, data = trTrain)
train_control <- trainControl(method="cv", number=10)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
rfPred <- predict(rfModel, newdata = teTrain)
confusionMatrix(rfPred, teTrain$classe)
rfModel2 <- randomForest(classe ~ ., preProcess = "pca", trControl = train_control, data = trTrain)
keep <- which(colSums(is.na(train)) < 19000)
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
train <- train[, -c(1, 2, grep("time", names(train)))]
colSums(is.na(train)) < 19000
which(colSums(is.na(train)) < 19000)
keep <- which(colSums(is.na(train)) < 19000)
train <- train[, keep]
rfPred2 <- predict(rfModel2, newdata = teTrain)
confusionMatrix(rfPred2, teTrain$classe)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
test <- test[, -c(1, 2, grep("time", names(test)))]
test <- test[, keep]
predictions <- predict(rfModel, newdata = test)
colnames(train)
colnames(test)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
train <- train[, -c(1, 2, grep("time", names(train)))]
sum(colSums(is.na(train)) == nrow(train))
keep <- which(colSums(is.na(train)) < 19000)
keep
keep <- which(colSums(is.na(train)) < 19000)
train <- train[, keep]
View(train)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
colnames(train) == colnames(test)
colnames(train)[160]
colnames(test)[160]
colnames(test)[160] <- "classe"
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
colnames(test)[160] <- "classe"
colnames(train)[160] == colnames(test)[160]
colnames(train) == colnames(test)
train <- train[, -c(1, 2, grep("time", names(train)))]
test <- test[, -c(1, 2, grep("time", names(test)))]
colnames(train) == colnames(test)
keep <- which(colSums(is.na(train)) < 19000)
train <- train[, keep]
test <- test[, keep]
colnames(train) == colnames(test)
predictions <- predict(rfModel, newdata = test)
sapply(test, class)
tables(sapply(test, class))
table(sapply(test, class))
table(sapply(train, class))
table(sapply(train, class))
table(sapply(test, class))
table(sapply(train, class))
table(sapply(test, class))
predictions <- predict(rfModel, newdata = test)
colnames(train)
colnames(test)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
test <- test[, -c(1, 2, grep("time", names(test)))]
test <- test[, keep]
colnames(test)
colnames(train) == colnames(test)
colnames(train) == colnames(test)
sapply(train, class)
sapply(test, class)
sapply(train, class) == sapply(test, class)
table(sapply(train, class) == sapply(test, class))
!table(sapply(train, class) == sapply(test, class))
!sapply(train, class) == sapply(test, class)
train[, table(sapply(test, class))]
!sapply(train, class) == sapply(test, class)
train[, !sapply(train, class) == sapply(test, class)]
class(train[, !sapply(train, class) == sapply(test, class)])
sapply(train[, !sapply(train, class) == sapply(test, class)], class)
sapply(test[, !sapply(train, class) == sapply(test, class)], class)
!sapply(train, class) == sapply(test, class)]
!sapply(train, class) == sapply(test, class)
which(!sapply(train, class) == sapply(test, class))
test[, which(!sapply(train, class) == sapply(test, class))] <- sapply(test[, which(!sapply(train, class) == sapply(test, class))], as.numeric)
sapply(train, class) == sapply(test, class)
table(sapply(train, class) == sapply(test, class))
predictions <- predict(rfModel, newdata = test)
test[, 55] <- as.factor(test[, 55])
predictions <- predict(rfModel, newdata = test)
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
# ===== Target variable =====
class(train$classe); levels(train$classe)
# ===== Useless variables =====
# Remove the index and user variables
train <- train[, -c(1, 2, grep("time", names(train)))]
# ===== NA values =====
# How many predictores have all their values equal to NA?
sum(colSums(is.na(train)) == nrow(train))
keep <- which(colSums(is.na(train)) < 19000)
train <- train[, keep]
nzv <- nearZeroVar(train, saveMetrics = T)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
test <- test[, -c(1, 2, grep("time", names(test)))]
test <- test[, keep]
colnames(train) == colnames(test)
test[, which(!sapply(train, class) == sapply(test, class))] <- sapply(test[, which(!sapply(train, class) == sapply(test, class))], as.numeric)
test[, 55] <- as.factor(test[, 55])
set.seed(1111)
indexTrain <- createDataPartition(train$classe, p = 0.60, list = F)
trTrain <- train[indexTrain, ]
teTrain <- train[-indexTrain, ]
train_control <- trainControl(method="cv", number=10)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
rfPred <- predict(rfModel, newdata = teTrain)
confusionMatrix(rfPred, teTrain$classe)
colnames(train)
test <- test[colnames(train)]
colnames(train[, -55])
test <- test[colnames(train[, -55])]
predictions <- predict(rfModel, newdata = test)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""))
test <- test[colnames(train[, -55])]
predictions <- predict(rfModel, newdata = test)
colnames(train) == colnames(test)
colnames(train[, -55]) == colnames(test)
sapply(train[, -55], class) == sapply(test, class)
table(sapply(train[, -55], class) == sapply(test, class))
url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""), header = T)
train <- train[, -c(1, 2, grep("time", names(train)))]
sum(colSums(is.na(train)) == nrow(train))
keep <- which(colSums(is.na(train)) < 19000)
train <- train[, keep]
rfPred <- predict(rfModel, newdata = teTrain)
confusionMatrix(rfPred, teTrain$classe)
test <- read.csv("test.csv", na.strings=c("NA","#DIV/0!",""), header = T)
test <- test[colnames(train[, -55])]
colnames(train[, -55]) == colnames(test)
predictions <- predict(rfModel, newdata = test)
test
predictions <- predict(rfModel, test)
sapply(test, class)
table(sapply(test, class))
table(sapply(train, class))
levels(test$new_window)
levels(test$new_window) <- c("no", "yes")
predictions <- predict(rfModel, test)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictions)
