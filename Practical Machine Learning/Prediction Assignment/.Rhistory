pairs(mtcars)
quantile(mpg_allcor, 0.75) < mpg_allcor
pairs(mtcars[, quantile(mpg_allcor, 0.75) < mpg_allcor])
mpg_allcor
pairs(mtcars[, c(T, quantile(mpg_allcor, 0.75) < mpg_allcor]))
pairs(mtcars[, c(T, quantile(mpg_allcor, 0.75) < mpg_allcor)])
model1 <- lm(mpg ~ factor(am), data = mtcars)
model1
summary(model1)
model1 <- lm(mpg ~ ., data = mtcars)
summary(model1)
model1 <- lm(mpg ~ wt + disp + factor(cyl), data = mtcars)
model3 <- lm(mpg ~ wt + disp + factor(cyl), data = mtcars)
summary(model3)
model2 <- lm(mpg ~ ., data = mtcars)
summary(model2)
model3 <- lm(mpg ~ wt + disp + factor(cyl), data = mtcars)
summary(model3)
model3 <- lm(mpg ~ am + wt + disp + factor(cyl), data = mtcars)
summary(model3)
model1 <- lm(mpg ~ factor(am), data = mtcars)
model2 <- lm(mpg ~ ., data = mtcars)
model3 <- lm(mpg ~ am + wt + disp + factor(cyl), data = mtcars)
anova(model1, model2, model3)
par(mfrow = c(2, 2))
plot(model2)
summary(model2)$r.square
model3 <- lm(mpg ~ am + wt + disp + factor(cyl), data = mtcars)
summary(model3)
library(swirl)
swirl()
fit <- lm(child ~ parent, galton)
summary(it)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs - rhs
allequal(lhs, rhs)
all.equal(lhs, rhs)
var(varChild)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes + varEst)
efit <- lm(accel ~ mag + dist, attenu)
mean(efit$residuals)
cov(efit$)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
library(AppliedPredictiveModeling)
library(caret)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
testing = adData[trainIndex,]
-
testing = adData[-trainIndex,]
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain
plot(CompressiveStrength, inTrain)
plot(mixtures$CompressiveStrength, inTrain)
plot(training$CompressiveStrength, inTrain)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
names(training)
featurePlot(training[, -9], training$CompressiveStrength)
index <- 1:nrow(training)
?gplot
library(ggplot2)
ggplot(training, aes(x = index))
ggplot(training, aes(x = index)) + geom_dotplot
plot(index, training$CompressiveStrength)
qplot(index, training$CompressiveStrength)
ggplot(training, aes(index) + geom_point()
)
)
ggplot(training, aes(index) + geom_point())
ggplot(training, aes(x=index) + geom_point())
ggplot(training, aes(x=index, y=CompressiveStrength) + geom_point())
ggplot(training, aes(x=index, y=CompressiveStrength)) + geom_point()
cut2(training)
cut2(training, 9)
cut2(training$CompressiveStrength, 8)
cut2(training$CompressiveStrength, 9)
ggplot(training, aes(x=index, y=CompressiveStrength), colour=cut2(training$CompressiveStrength, 9)) + geom_point()
?apply
summary(training)
ggplot(training, aes(x=index, y=CompressiveStrength), colour=)) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=)) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength)) + geom_point()
fcolor <- cut2(training$cement, 4)
training$cement
fcolor <- cut2(training$Cement, 4)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, 4))),
to = c("red", "blue", "yellow", "green"))
?mapvalues
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, 4))),
to = c("red", "blue", "yellow", "green"))
cut2(training$Cement, 4)
cut2(training$Cement, 4)
training$Cement
cut2(training$Cement, g=4)
summary(training)
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, g=4))),
to = c("red", "blue", "yellow", "green"))
fcolor <- mapvalues(cut2(training$Cement, g=4),
from = levels(factor(cut2(training$Cement, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- mapvalues(cut2(training$FlyAsh, g=4),
from = levels(factor(cut2(training$FlyAsh, g=4))),
to = c("red", "blue", "yellow", "green"))
cut2(training$FlyAsh, g=4)
training$FlyAsh
summary(training)
summary(training)
fcolor <- mapvalues(cut2(training$Age, g=4),
from = levels(factor(cut2(training$Age, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- cut2(training$Age, g=4)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$BlastFurnaceSlag, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, training, geom = "hist")
qplot(Superplasticizer, training, geom = "histogram")
summary(training$Superplasticizer)
hist(training$Superplasticizer)
log(0)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)[substr(names(training), 1, 2) == "IL"]
library(caret)
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProcess(trainingIL, method = "pca", pcaComp = 7)
preProc <- preProcess(trainingIL, method = "pca", pcaComp = 7)
?preProcess
preProc$numComp
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.9)
preProc
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.8)
preProc
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?cblind
newtraining <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
modelFit <- train(newtraining$training$diagnosis ~ ., method = "glm", data = newtraining)
names(newtraining)[13]
names(newtraining)[13] <- "diag"
modelFit <- train(newtraining$diag ~ ., method = "glm", data = newtraining)
modelFitPCA <- train(newtraining$diag ~ ., method = "glm", preProcess = "pca", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = training2)
inTrain = createDataPartition(newtraining$diag, p = 3/4)[[1]]
training2 = newtraining[ inTrain,]
testing2 = newtraining[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
install.packages("e1071")
install.packages("e1071")
install.packages("e1071")
install.packages("~/Downloads/e1071_1.6-4.tar.gz", repos = NULL, type = "source")
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
modelFitPCA <- train(training2$diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
confusionMatrix(modelFit)
predictors
predictorsIL <- predictors[, substr(names(confusionMatrix(modelFit)), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
predictorsIL
predictorsIL <- predictors[, substr(names(predictors), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictions1 <- predict(modelFit, newdata = testing2)
confusionMatrix(modelFit, predictions1)
confusionMatrix(predictions1, testing2)
confusionMatrix(predictions1, testing2$diag)
predictions2 <- predict(modelFitPCA, newdata = testing2)
confusionMatrix(predictions2, testing2$diag)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, p = 0.7, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
set.seed(125)
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
install.packages("rattle")
install.packages("rattle")
library(rattle)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("rpart.plot")
install.packages("rpart.plot")
fancyRpartPlot(CARTmodel$finalModel)
CARTmodel$finalModel
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(olive)
data <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]
data(olive)
olive <- olive[,-1]
data(olive)
all.equal(olive$Region, olive$Area)
equal(olive$Region, olive$Area)
all(olive$Region, olive$Area)
class(olive$Region)
class(olive$Area)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
set.seed(123)
library(pgmm)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- olive[trainIndex, ]
test <- olive[-trainIndex, ]
?train
getModelInfo()
treeModel <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
treeModel$finalModel
fancyRpartPlot(treeModel$finalModel)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fitModel <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
values <- testSA$chd
predictions <- predict(fitModel, testSA)
missClass(values, predictions)
values <- trainSA$chd
predictions <- predict(fitModel, trainSA)
missClass(values, predictions)
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
vowel.train
y <- factor()
train <- cbind(data(vowel.train), y)
train <- cbind(data(vowel.train), as.factor(y))
train <- data(vowel.train)
train <- cbind(train, as.factor(y))
data(vowel.train)
data(vowel.test)
vowel.train
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
?varImp
varImp(rdmforest)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
data$Case
factor(data$Case)
factor(data$Case)
?factor
levels(data$Case)
data$Case == levels(data$Case)[1]
levels(data$Case)[1]
data$Case == levels(data$Case)[2]
levels(data$Case)[2]
trainIndex <- data$Case == levels(data$Case)[2]
training <- data[trainIndex, ]
-trainIndex
?T
c(V, F) == F
c(V, F)
c(T, F) == F
testing <- data[trainIndex == F, ]
set.seed(125)
fitModel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(fitModel$finalModel)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
varImp(rdmforest)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
varImp(rdmforest)
order(varImp(rdmforest))
?order
sort(varImp(rdmforest))
sort(order(varImp(rdmforest)))
order(varImp(rdmforest))
setwd("~/Desktop/repos/datasciencecoursera/Practical Machine Learning/Prediction Assignment")
library(lattice)
library(ggplot2)
library(caret)
library(rattle)
train <- read.csv("train.csv", na.strings=c("NA","#DIV/0!",""))
train <- train[, -c(1, 2, grep("time", names(train)))]
train <- train[, colSums(is.na(train)) < 19000]
set.seed(1111)
rfModel <- train(classe ~ ., method = "rf", preProcess=c("center", "scale"), trControl=trainControl(method = "cv", number = 4), data = trTrain)
indexTrain <- createDataPartition(train$classe, p = 0.60, list = F)
trTrain <- train[indexTrain, ]
teTrain <- train[-indexTrain, ]
rfModel <- train(classe ~ ., method = "rf", preProcess=c("center", "scale"), trControl=trainControl(method = "cv", number = 4), data = trTrain)
rfModel <- randomForest(classe ~ ., data = trTrain, importance = TRUE)
train_control <- trainControl(method="cv", number=10)
train_control <- trainControl(method="cv", number=10)
rfModel <- train(classe ~ ., method = "rf", trControl = train_control, data = trTrain)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
rfPred <- predict(rfModel, newdata = teTrain)
confusionMatrix(rfPred, teTrain$classe)
rfModel2 <- randomForest(classe ~ ., preProcess = "pca", trControl = train_control, data = trTrain)
rfPred <- predict(rfModel2, newdata = teTrain)
confusionMatrix(rfPred2, teTrain$classe)
rfPred2 <- predict(rfModel2, newdata = teTrain)
confusionMatrix(rfPred2, teTrain$classe)
varImp(rfPred)
varImp(rfModel)
plot(varImp(rfModel), top = 20)
plot(varImp(rfModel))
plot(varImp(rfModel), top = 10)
train_control <- trainControl(method="cv", number=10)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain, importance = T)
plot(varImp(rfModel), top = 10)
varImp(rfModel)
qplot(varImp(rfModel), top = 10)
train_control <- trainControl(method="cv", number=10)
rfModel <- randomForest(classe ~ ., trControl = train_control, data = trTrain)
