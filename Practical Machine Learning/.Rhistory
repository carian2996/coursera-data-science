library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(ggplot2)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain
plot(CompressiveStrength, inTrain)
plot(mixtures$CompressiveStrength, inTrain)
plot(training$CompressiveStrength, inTrain)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
names(training)
featurePlot(training[, -9], training$CompressiveStrength)
index <- 1:nrow(training)
?gplot
library(ggplot2)
ggplot(training, aes(x = index))
ggplot(training, aes(x = index)) + geom_dotplot
plot(index, training$CompressiveStrength)
qplot(index, training$CompressiveStrength)
ggplot(training, aes(index) + geom_point()
)
)
ggplot(training, aes(index) + geom_point())
ggplot(training, aes(x=index) + geom_point())
ggplot(training, aes(x=index, y=CompressiveStrength) + geom_point())
ggplot(training, aes(x=index, y=CompressiveStrength)) + geom_point()
cut2(training)
cut2(training, 9)
cut2(training$CompressiveStrength, 8)
cut2(training$CompressiveStrength, 9)
ggplot(training, aes(x=index, y=CompressiveStrength), colour=cut2(training$CompressiveStrength, 9)) + geom_point()
?apply
summary(training)
ggplot(training, aes(x=index, y=CompressiveStrength), colour=)) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=)) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength)) + geom_point()
fcolor <- cut2(training$cement, 4)
training$cement
fcolor <- cut2(training$Cement, 4)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, 4))),
to = c("red", "blue", "yellow", "green"))
?mapvalues
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, 4))),
to = c("red", "blue", "yellow", "green"))
cut2(training$Cement, 4)
cut2(training$Cement, 4)
training$Cement
cut2(training$Cement, g=4)
summary(training)
fcolor <- mapvalues(splitOn,
from = levels(factor(cut2(training$Cement, g=4))),
to = c("red", "blue", "yellow", "green"))
fcolor <- mapvalues(cut2(training$Cement, g=4),
from = levels(factor(cut2(training$Cement, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- mapvalues(cut2(training$FlyAsh, g=4),
from = levels(factor(cut2(training$FlyAsh, g=4))),
to = c("red", "blue", "yellow", "green"))
cut2(training$FlyAsh, g=4)
training$FlyAsh
summary(training)
summary(training)
fcolor <- mapvalues(cut2(training$Age, g=4),
from = levels(factor(cut2(training$Age, g=4))),
to = c("red", "blue", "yellow", "green"))
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
fcolor <- cut2(training$Age, g=4)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=fcolor)) + geom_point()
index <- 1:nrow(training)
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Cement, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$BlastFurnaceSlag, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$FlyAsh, g=4))) + geom_point()
ggplot(training, aes(x=index, y=CompressiveStrength, colour=cut2(training$Age, g=4))) + geom_point()
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, training, geom = "hist")
qplot(Superplasticizer, training, geom = "histogram")
summary(training$Superplasticizer)
hist(training$Superplasticizer)
log(0)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)[substr(names(training), 1, 2) == "IL"]
library(caret)
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProcess(trainingIL, method = "pca", pcaComp = 7)
preProc <- preProcess(trainingIL, method = "pca", pcaComp = 7)
?preProcess
preProc$numComp
trainingIL <- training[, substr(names(training), 1, 2) == "IL"]
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.9)
preProc
preProc <- preProcess(trainingIL, method = "pca", thresh = 0.8)
preProc
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
?cblind
newtraining <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
modelFit <- train(newtraining$training$diagnosis ~ ., method = "glm", data = newtraining)
names(newtraining)[13]
names(newtraining)[13] <- "diag"
modelFit <- train(newtraining$diag ~ ., method = "glm", data = newtraining)
modelFitPCA <- train(newtraining$diag ~ ., method = "glm", preProcess = "pca", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = newtraining)
modelFit <- train(diag ~ ., method = "glm", data = training2)
inTrain = createDataPartition(newtraining$diag, p = 3/4)[[1]]
training2 = newtraining[ inTrain,]
testing2 = newtraining[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
install.packages("e1071")
install.packages("e1071")
install.packages("e1071")
install.packages("~/Downloads/e1071_1.6-4.tar.gz", repos = NULL, type = "source")
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca",
data = training2,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
modelFitPCA <- train(training2$diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
confusionMatrix(modelFit)
predictors
predictorsIL <- predictors[, substr(names(confusionMatrix(modelFit)), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
predictorsIL
predictorsIL <- predictors[, substr(names(predictors), 1, 2) == "IL"]
preProc <- preProcess(predictorsIL, method = "pca", thresh = 0.8)
preProc
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
newdata <- cbind(training[, substr(names(training), 1, 2) == "IL"], training$diagnosis)
names(newdata)[13] <- "diag"
inTrain = createDataPartition(newdata$diag, p = 3/4)[[1]]
training2 = newdata[ inTrain,]
testing2 = newdata[-inTrain,]
modelFit <- train(diag ~ ., method = "glm", data = training2)
modelFitPCA <- train(diag ~ ., method = "glm", preProcess = "pca", data = training2, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
predictions1 <- predict(modelFit, newdata = testing2)
confusionMatrix(modelFit, predictions1)
confusionMatrix(predictions1, testing2)
confusionMatrix(predictions1, testing2$diag)
predictions2 <- predict(modelFitPCA, newdata = testing2)
confusionMatrix(predictions2, testing2$diag)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, p = 0.7, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
set.seed(125)
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
install.packages("rattle")
install.packages("rattle")
library(rattle)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("rpart.plot")
install.packages("rpart.plot")
fancyRpartPlot(CARTmodel$finalModel)
CARTmodel$finalModel
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Case ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
data(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
data(segmentationOriginal)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
CARTmodel$finalModel
fancyRpartPlot(CARTmodel$finalModel)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
set.seed(125)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
trainIndex <- createDataPartition(data$Case, list = F)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
CARTmodel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(CARTmodel$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(olive)
data <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- data[trainIndex, ]
test <- data[-trainIndex, ]
data(olive)
olive <- olive[,-1]
data(olive)
all.equal(olive$Region, olive$Area)
equal(olive$Region, olive$Area)
all(olive$Region, olive$Area)
class(olive$Region)
class(olive$Area)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
set.seed(123)
library(pgmm)
data(olive)
olive <- olive[,-1]
trainIndex <- createDataPartition(olive$Area, p = 0.7, list = F)
train <- olive[trainIndex, ]
test <- olive[-trainIndex, ]
?train
getModelInfo()
treeModel <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
treeModel$finalModel
fancyRpartPlot(treeModel$finalModel)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fitModel <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
method = "glm", family = "binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
values <- testSA$chd
predictions <- predict(fitModel, testSA)
missClass(values, predictions)
values <- trainSA$chd
predictions <- predict(fitModel, trainSA)
missClass(values, predictions)
data(vowel.train)
data(vowel.test)
data(vowel.train)
data(vowel.test)
vowel.train
y <- factor()
train <- cbind(data(vowel.train), y)
train <- cbind(data(vowel.train), as.factor(y))
train <- data(vowel.train)
train <- cbind(train, as.factor(y))
data(vowel.train)
data(vowel.test)
vowel.train
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
?varImp
varImp(rdmforest)
library(caret)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
data <- data.frame(segmentationOriginal)
data$Case
factor(data$Case)
factor(data$Case)
?factor
levels(data$Case)
data$Case == levels(data$Case)[1]
levels(data$Case)[1]
data$Case == levels(data$Case)[2]
levels(data$Case)[2]
trainIndex <- data$Case == levels(data$Case)[2]
training <- data[trainIndex, ]
-trainIndex
?T
c(V, F) == F
c(V, F)
c(T, F) == F
testing <- data[trainIndex == F, ]
set.seed(125)
fitModel <- train(Class ~ ., method = "rpart", data = training)
fancyRpartPlot(fitModel$finalModel)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rdmforest <- train(y ~ ., method = "rf", data = vowel.train, prox = T)
varImp(rdmforest)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
rdmforest <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(rdmforest))
varImp(rdmforest)
order(varImp(rdmforest))
?order
sort(varImp(rdmforest))
sort(order(varImp(rdmforest)))
order(varImp(rdmforest))
library(caret)
library(rattle)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- factor(data(vowel.train)$y)
train <- data(vowel.train)
train <- factor(train$y)
data(vowel.train)
data(vowel.train)
data(vowel.test)
train <- vowel.train
test <- vowel.test
train$y <- factor(train$y)
test$y <- factor(test$y)
set.seed(33833)
rfModel <- train(y ~ ., method = "rf", data = train)
booModel <- train(y ~ ., method = "gbm", data = train)
rfpred <- predict(rfModel, test)
boopred <- predict(booModel, test)
confusionMatrix(rfpred, test$y)
confusionMatrix(boopred, test$y)
qplot(rfpred, boopred, data = test)
qplot(rfpred, boopred, colour = test$y, data = test)
rfresults <- confusionMatrix(rfpred, test$y)
booresults <- confusionMatrix(boopred, test$y)
rfresults$table
rfresults$positive
abs(rfpred - boopred)
rfpred
boopred
as.numeric(rfpred)
abs(as.numeric(rfpred) - as.numeric(boopred))
sum(as.numeric(boopred) - as.numeric(rfpred))
sum(as.numeric(rfpred) - as.numeric(boopred))
abs(sum(as.numeric(rfpred) - as.numeric(boopred)) / nrow(test$y))
sum(as.numeric(rfpred) - as.numeric(boopred))
nrow(test$y)
nrow(test)
sum(as.numeric(rfpred) - as.numeric(boopred))/nrow(test)
abs(sum(as.numeric(rfpred) - as.numeric(boopred))/nrow(test))
set.seed(3433)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
frModel <- train(diagnosis ~ ., method = "rf", data = training)
botModel <- train(diagnosis ~ ., method = "gbm", data = training)
ldaModel <- train(diagnosis ~ ., method = "lda", data = training)
frpred <- predictors(frModel, testing)
botpred <- predictors(botModel, testing)
ldapred <- predictors(ldaModel, testing)
sqrt(sum((frpred - testing$diagnosis)^2))
confusionMatrix(frpred, testing$diagnosis)
frpred
frpred <- predict(frModel, testing)
botpred <- predict(botModel, testing)
ldapred <- predict(ldaModel, testing)
confusionMatrix(frpred, testing$diagnosis)
confusionMatrix(botpred, testing$diagnosis) #
confusionMatrix(ladpred, testing$diagnosis) #
confusionMatrix(ldapred, testing$diagnosis) #
predDF <- data.frame(frpred, botpred, ldapred, diagnosis = testing$diagnosis)
combModel <- train(diagnosis ~ ., method = "gam", data = predDF)
combpred <- predict(combModel, predDF)
confusionMatrix(combModel, predDF$diagnosis) # 0.7683
confusionMatrix(combpred, predDF$diagnosis) # 0.7683
combModel <- train(diagnosis ~ ., method = "rf", data = predDF)
predDF <- data.frame(frpred, botpred, ldapred, diagnosis = testing$diagnosis)
combModel <- train(diagnosis ~ ., method = "rf", data = predDF)
combpred <- predict(combModel, predDF)
confusionMatrix(combpred, predDF$diagnosis) # 0.7683
frModel <- train(diagnosis ~ ., method = "rf", data = training, trControl = trainControl(number = 4))
c2 <- confusionMatrix(botpred, testing$diagnosis) # 0.7927 ***
c3 <- confusionMatrix(ldapred, testing$diagnosis) # 0.7683
c1 <- confusionMatrix(frpred, testing$diagnosis) # 0.7683
predDF <- data.frame(frpred, botpred, ldapred, diagnosis = testing$diagnosis)
combModel <- train(diagnosis ~ ., method = "rf", data = predDF)
combpred <- predict(combModel, predDF)
c4 <- confusionMatrix(combpred, predDF$diagnosis) # 0.7683
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
library(lattice)
library(ggplot2)
library(caret)
library(rattle)
library(gbm)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lassoModel <- train(CompressiveStrength ~ ., method = "lasso")
lassoModel <- train(CompressiveStrength ~ ., method = "lasso", data = training)
?plot.enet
plot.enet(lassoModel)
plot.enet(enet(lassoModel), xvar = "penalty")
plot(enet(lassoModel), xvar = "penalty")
plot.enet(lassoModel$finalModel, xvar = "penalty", use.color = T)
setwd("~/Desktop/repos/datasciencecoursera/Practical Machine Learning")
download.file(url = url, destfile = "nvisit.csv", method = "curl")
url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(url = url, destfile = "nvisit.csv", method = "curl")
