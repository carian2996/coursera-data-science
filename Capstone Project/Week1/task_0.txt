Task to accomplish
- Obtain the data.
- Familiarizing yourself with NLP and text mining.

Questions to consider
1. What do teh data look like?

===== Organización de los datos =====
Los datos están organizados en cuatro idiomas:
	- Alemán
	- Inglés
	- Finés
	- Ruso
Cada uno de ellos con tres diferentes origenes de corpora (A set of documents or individual sentences that have been hand-annotated with the correct values to be learned).
	- Blogs
	- Noticias / Periódicos
	- Twitter

=====  Tipo de datos =====
Los datos están organizados en diferentes corpus. Un conjunto de documentos o sentencias individuales que han sido escritos a mano con los valores correctos para ser aprendidos.

===== Tamaño de los datos =====
El tamaño de los archivo varia desde "fi_FI.twitter.txt" de 24.75 Mb hasta "en_US.blogs.txt" con 205.25 Mb.

En general, para el corpus de Twitter, las sentencias no rebasan las 144 palabras (como regla de Twiiter), sin embargo, en el corpus de blogs, las palabras variar desde 1 hasta cientos.

2. Where do the data come from?

===== Origen de los datos ======
Originalmente, los datos vienen de la página del Capstone Project de la especilidad Data Science de Coursera en:
	
	https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip

===== Más información =====
Los corpus en data fueron recolectados por HC Corpora (http://www.corpora.heliohost.org/index.html). La corpora fueron recolectados de fuentes públicas y disponibles por un web crawler.

El web crawler verifíca el tipo de lenguaje, para así conseguir cuanto más texto del idioma deseado.

Se pueden encontrar lineas enteras de texto en un cierto corpus. Esto por dos razones diferentes:

	1. Lenguajes similares.
	2. Lenguajes extranjeros añadidos. Al usar dos tipos de lenguaje en un cierto texto (entrada de blog, twit, párrafo, oración, etcétera).

3. Can you think of any other data sources that might help you in this project?

===== Datos adicionales =====

	1. Corpus generados por procesadores de texto, disponibles y libres. Generados por uno mismo.
	2. Obras completas de texo, de un lenguaje no sofisticado.

4 What are the common steps in natural language processing?

===== ¿Qué es el PLN? =====
EL PLN es un campo de la ciencia computacional y la linguística concerniente a las interacciones entre computadoras y los lenguajes humanos (naturales). EL PLN se entiende como un problema completo dentro del área de Inteligencia Artificial.

Los algoritmos actuales en PNL están basado en Machine Learning, especialmente en Statistical Machine Learning, el entendimiento de los algoritmos requiere un número diferentes de campos, incluyendo:
	
	- Lingüística.
	- Ciencias de la Computación.
	- Estadística (en especial Bayesiana).
	- Álgebra Lineal.
	- Teoría de Optimización.

Los pasos básicos para el PLN, son los siguientes:

	1.
	2. 
	3. 
	5. 

5. What are some common issues in the analysis of text data?

===== Problemas en el análisis de datos de texto =====
	
	- Diferentes tipos de algoritmos en machine learning que han sido aplicados al PLN producen reglas tipo "si-entonces" similares a las de algoritmos antiguos (tal es es caso de los árboles de decisión). 
	Sin embargo, modelos estadísticos producen sistemas menos rígidos, con decisiones probabilisticas basadas en pesos asignados en valores reales para cada característica de entrada. Tales algorimos tienen cierta ventaja al permitir diferentes (y posibles) respuestas en lugar de solo una. Generalmente son algos más robustos.


6. What is the relationship between NLP and the concepts you have learned in the Specialization?

===== El uso del Machine Learning en PLN =====
El uso de marchine learning en PLN se vasa en aprender automáticamente las reglas generales de lenguaje a través de grandes cantindades de corpora como ejemplos típicos del mundo real. Un corpus, es un conjunto de documentos que han sido escritos a mano con los valores correctos listos para ser aprendidos.

Una típica implementación basada en machine learning constan de dos pasos, un paso de entrenamiento y un paso de evaluación. 

	Entrenamiento: Se analiza el corpus de entrenamiento y se genera un modelo de entrenamiento, que consiste en reglas automáticamente generadas. El modelo generado es típicamente el mejor modelo que puede ser encontrado y al mismo tiempo, el más simple (para evitar el sobre ajuste en los datos de entrenamiento, para poder predecir en datos nunca vistos). 

	Evaluación: El modelo de aprendizaje es usado para predicción. Una parte importante del desarrollo de cualquier algoritmo de predicción es la evaluación del modelo con datos nuevos y nunca probados.

IMPORTANTE: Es crítico que los datos usados para la evaluación no seas los mismos que los datos de entrenamientos, pues, de otra manera, la exactitud de la evaluación sería más alta de lo esperado.