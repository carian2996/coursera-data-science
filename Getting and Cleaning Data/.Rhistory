rm(palindrome)
palindromo("Hola")
?floor
p="Hola"
nchar(p)
nchar(p)/2
floor(nchar(p)/2)
1:floor(nchar(p)/2)
i=1
nchar(p) - i + 1
r <- nchar(p) - i + 1
substr(p, i, i)
substr(p, r, r)
i=2
r <- nchar(p) - i + 1
r
substr(p, i, i)
substr(p, r, r)
palindromo <- function(p){
for(i in 1:floor(nchar(p)/2)){
r <- nchar(p) - i + 1
if(substr(p, i, i) != substr(p, r, r)){
"Esto no es un palindromo"
} else{
"Esto es un palindromo"
}
}
}
palindromo("Hola")
palindromo <- function(p) {
for(i in 1:floor(nchar(p)/2) ) {
r <- nchar(p) - i + 1
if ( substr(p, i, i) != substr(p, r, r) ) return(FALSE)
}
TRUE
}
palindromo("Hola")
palindromo("Ana")
palindromo("reconocer")
palindromo <- function(p) {
for(i in 1:floor(nchar(p)/2) ) {
r <- nchar(p) - i + 1
if ( substr(p, i, i) != substr(p, r, r) ) return("Intentalo de nuevo")
}
"Felicidades! Tienes un palindromo en tus manos"
}
palindromo("reconocer")
conexion <- url("http://biostat.jhsph.edu/~jleek/contact.html")
HTMLCode <- readLines(conexion)
close(conexion)
head(HTMLCode)
HTMLCode[10]
nchar(HTMLCode[10])
nchar((HTMLCode)[10, 20, 30, 100])
nchar(HTMLCode[20])
nchar(HTMLCode[10])
nchar(HTMLCode[20])
nchar(HTMLCode[30])
nchar(HTMLCode[100])
class(HTMLCode)
dim(HTMLCode)
read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
?read.fwf
data_fwf <- read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths = c(1, 2, 3))
data_fwf <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(data_fwf)
sum(head(data_fwf)[, 4])
class(data_fwf)
apply(data_fwf, 2, sum)
apply(data_fwf, 2, sum())
apply(data_fwf, 2, sum
)
str(data_fwf)
apply(data_fwf[-1], 2, sum)
View(data_fwf)
View(data_fwf)
apply(data_fwf[6, 7], 2, sum)
data_fwf[6, 7]
apply(data_fwf[, c(6, 7)], 2, sum)
sum(apply(data_fwf[, c(6, 7)], 2, sum))
sum(apply(data_fwf[, c(8, 9)], 2, sum))
sum(apply(data_fwf[, c(6, 7)], 2, sum))
apply(data_fwf[, c(6, 7)], 2, sum)
data_fwf <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
close(con)
close(con)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(12,7,4,9,4,9,4,9,4))
close(con)
con <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(12,7,4,9,4,9,4,9,4))
close(con)
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(12,7,4,9,4,9,4,9,4))
close(con)
head(data_fwf)
class(data_fwf)
str(data_fwf)
apply(data_fwf[, c(6, 7)], 2, sum)
sum(apply(data_fwf[, c(6, 7)], 2, sum))
sum(apply(data_fwf[, c(8, 9)], 2, sum))
View(data_fwf)
sum(apply(data_fwf[, c(8, 9)], 2, sum))
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,9,4,9,4,9,4,9,4))
close(con)
View(data_fwf)
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
View(data_fwf)
apply(data_fwf[, c(8, 9)], 2, sum)
sum(apply(data_fwf[, c(8, 9)], 2, sum))
close(con)
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
View(data_fwf)
sum(apply(data_fwf[, c(8, 9)], 2, sum))
sum(data_fwf[, 4])
library(httr)
require(httpuv)
install.packages(c("httpuv", "jsonlite"))
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "ddb0d599de51ccd02f4b", secret="6af1109f6ecf442d292425087d49bb13d9bbe9c8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "041fe7d5df66f8834c1b", secret="85ab3505e732f175f8f4369367ee4db1abdbe4a6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
output[[4]]
output[[4]]$name
lala <- output[[4]]
lala$created_at
lala$creat
list(output[[5]]$name, output[[5]]$creat)
conexion <- url("http://biostat.jhsph.edu/~jleek/contact.html")
HTMLCode <- readLines(conexion)
close(conexion)
class(HTMLCode)
head(HTMLCode)
nchar(HTMLCode[10])
nchar(HTMLCode[20])
nchar(HTMLCode[30])
nchar(HTMLCode[100])
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
sum(data_fwf[, 4])
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
fecha_ini <- as.Date("01/01/2014", format = "%d/%m/%Y")
fechas <- fecha_ini + (1:plazo)
plazo = 100
fecha_ini <- as.Date("01/01/2014", format = "%d/%m/%Y")
fechas <- fecha_ini + (1:plazo)
fechas
fechas <- fecha_ini + (0:plazo)
fechas
fechas <- fecha_ini + 0:(plazo-1)
fechas
beca <- fechas[format(fechas, "%d")=="01"]
beca
beca <- fechas[format(fechas, "%d")=="1"]
beca
beca <- fechas[format(fechas, "%d")=="01"]
beca
beca <- data.frame(dates=fechas[format(fechas, "%d")=="01"])
beca
beca$cantidad <- 1000
data$inc <- 1
beca$inc <- 1
beca$exp <- 0
beca$exp[data$inc==0] <- 1
View(beca)
beca$concepto <- "Aqui va un concepto"
View(beca)
beca <- data.frame(dates=fechas[format(fechas, "%d")==1])
beca
beca <- data.frame(dates=fechas[format(fechas, "%d")=="01"])
beca$cantidad <- 1000
recurrentes <- lis(beca=c(), banxico=c(), mesada=c())
recurrentes <- list(beca=c(), banxico=c(), mesada=c())
recurrentes
recurrentes <- list(beca=c(), banxico=c(), mesada=c())
beca <- list(cantidad=1000, fecha_ini=as.Date("01/01/2014", format = "%d/%m/%Y"), tipo=1)
banxico <- list(cantidad=1000, fecha_ini=as.Date("28/02/2014", format = "%d/%m/%Y"), tipo=1)
mesada <- list(cantidad=, fecha_ini=as.Date("05/01/2014", format = "%d/%m/%Y"), tipo=1)
mesada <- list(cantidad=500, fecha_ini=as.Date("05/01/2014", format = "%d/%m/%Y"), tipo=1)
recurrentes <- list(beca=beca, banxico=banxico, mesada=mesada)
recurrentes
library(datasets)
data(iris)
?iris
data(mtcars)
?mtcars
head(iris)
levels(iris$Species)
medias <- sapply(split(iris, iris$Species), function(x) colMeans(x[, colnames(iris)[1:4]]))
medias["Sepal.Length", "virginica"]
virginica <- split(iris, iris$Species)$virginica
mean(virginica$Sepal.Length)
mean(iris$Sepal.Length[iris$Species=="virginica"])
# ===== Question 2 =====
class(iris)
apply(iris, 2, mean) # Contiene la variable "Species"
apply(iris[, 1:4], 2, mean) # Solo contiene las variables numÃ©ricas
# ===== Question 3 =====
head(mtcars)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
# ===== Question 4 =====
medias_hp_cilindro <- sapply(split(mtcars$hp, mtcars$cyl), mean)
abs(medias_hp_cilindro[1] - medias_hp_cilindro[3])
?bin
?rbin
?rbin()
?rbinom
pbinom(12, 100, .1)
pbinom(12, 100, .1) - pbinom(10, 100, .1)
pbinom(22, 100, .1) - pbinom(20, 100, .1)
pbinom(22, 100, 2/10) - pbinom(20, 100, 2/10)
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
install.packages(c("boot", "class", "cluster", "codetools", "data.table", "httr", "jsonlite", "KernSmooth", "labeling", "maps", "MASS", "mgcv", "Rcpp", "RCurl", "spam", "swirl", "testthat", "xlsx", "xlsxjars"))
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = F)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "IN" | country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux_gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "041fe7d5df66f8834c1b", secret="85ab3505e732f175f8f4369367ee4db1abdbe4a6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[5]]$name, output[[5]]$creat)
conexion <- url("http://biostat.jhsph.edu/~jleek/contact.html")
HTMLCode <- readLines(conexion)
close(conexion)
class(HTMLCode)
head(HTMLCode)
nchar(HTMLCode[10])
nchar(HTMLCode[20])
nchar(HTMLCode[30])
nchar(HTMLCode[100])
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
sum(data_fwf[, 4])
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
library(dplyr)
cran <- tbl_df()
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package)
summarize(by_package, mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
??chain
submit()
submit()
submit()
submit()
swirl()
library(swirl)
swirl()
0
exit()
exit
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(packgae = lubridate)
help(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
day(this_day)
wday(this_day)
wday(this_day, label = T)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989-04-17")
ymd("1989 May 17")
myd("March 12, 1975")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("192012--")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = hour(now()), minutes = minute(now()))
this_moment
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + munites(50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
mdy("June 17, 2008", tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
setwd("~/Desktop/repos/datasciencecoursera/Getting and Cleaning Data")
url <- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url, "communities.csv")
data <- read.csv("communities.csv")
names(data)
strsplit(names(data), "wgtp")
strsplit(names(data), "wgtp")[123]
strsplit(names(data), "wgtp")[[123]]
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, "grossdomesticproduct.csv")
data <- read.csv("grossdomesticproduct.csv")
head(data)
head(data, 10)
mean(sub(",", "", data$X.3))
sub(",", "", data$X.3)
data$X.3
sub(",", "", data$X.3)
gsub(",", "", data$X.3)
as.numeric(gsub(",", "", data$X.3))
mean(as.numeric(gsub(",", "", data$X.3)))
mean(as.numeric(gsub(",", "", data$X.3)), na.rm = T)
data$X.3
View(data)
data$X.3[!is.na(data$X.3)]
!is.na(data$X.3)
data$X.3
gsub(",", "", data$X.3)
as.numeric(gsub(",", "", data$X.3))
as.numeric(gsub(",", "", data$X.3))[!is.na(as.numeric(gsub(",", "", data$X.3)))]
View(data)
View(data)
data$X.3[5:194]
mean(as.numeric(gsub(",", "", data$X.3[5:194])))
grep("^United", data$X.2[5:194])
View(data)
url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, "educationaldata.csv")
dataeducation <- read.csv("educationaldata.csv")
View(dataeducation)
View(dataeducation)
View(data)
match(dataeducation$CountryCode, data$X[5:194])
sum(!is.na(match(dataeducation$CountryCode, data$X[5:194])))
View(dataeducation)
match(dataeducation$CountryCode, data$X[5:194])
match(data$X[5:194], dataeducation$CountryCode)
data$X[5:194][is.na(match(data$X[5:194], dataeducation$CountryCode))]
View(data)
match(data$X[5:194], dataeducation$CountryCode)
rm.na(match(data$X[5:194], dataeducation$CountryCode))
na.omit(match(data$X[5:194], dataeducation$CountryCode))
dataeducation2 <- dataeducation[na.omit(match(data$X[5:194], dataeducation$CountryCode)), ]
View(dataeducation2)
grep("^Fiscal", dataeducation2$Special.Notes)
length(grep("^Fiscal", dataeducation2$Special.Notes))
junefiscal <- dataeducation2[grep("^Fiscal", dataeducation2$Special.Notes), ]
View(junefiscal)
junefiscal <- dataeducation2[grep("^Fiscal & June", dataeducation2$Special.Notes), ]
junefiscal <- dataeducation2[grep("^Fiscal", dataeducation2$Special.Notes), ]
View(junefiscal)
grep(c("^Fiscal", "June"), dataeducation2$Special.Notes)
junefiscal <- dataeducation2[grep("June", dataeducation2$Special.Notes), ]
View(junefiscal)
junefiscal <- dataeducation2[grep("^Fiscal | June", dataeducation2$Special.Notes), ]
View(junefiscal)
unique(grep("^Fiscal | June", dataeducation2$Special.Notes, value = T, fixed = T))
unique(grep("^Fiscal | June", dataeducation2$Special.Notes, value = T))
unique(grep("^Fiscal | June", dataeducation2$Special.Notes))
junefiscal <- dataeducation2[unique(grep("^Fiscal | June", dataeducation2$Special.Notes)), ]
View(junefiscal)
View(junefiscal)
junefiscal <- dataeducation2[unique(grep("Fiscal year end: June", dataeducation2$Special.Notes)), ]
View(junefiscal)
nrow(junefiscal)
library(quantmod)
install.packages(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn
head(amzn)
amzn[, 1]
sampleTimes
class(sampleTimes)
library(lubridate)
year(sampleTimes)
year(sampleTimes) == "2012"
n(amzn[year(sampleTimes) == "2012"])
nrow(amzn[year(sampleTimes) == "2012"])
sum(wday(sampleTimes) == 2 & year(sampleTimes) == "2012")
sum(year(sampleTimes) == "2012")
