output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
output[[4]]
output[[4]]$name
lala <- output[[4]]
lala$created_at
lala$creat
list(output[[5]]$name, output[[5]]$creat)
conexion <- url("http://biostat.jhsph.edu/~jleek/contact.html")
HTMLCode <- readLines(conexion)
close(conexion)
class(HTMLCode)
head(HTMLCode)
nchar(HTMLCode[10])
nchar(HTMLCode[20])
nchar(HTMLCode[30])
nchar(HTMLCode[100])
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
sum(data_fwf[, 4])
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
fecha_ini <- as.Date("01/01/2014", format = "%d/%m/%Y")
fechas <- fecha_ini + (1:plazo)
plazo = 100
fecha_ini <- as.Date("01/01/2014", format = "%d/%m/%Y")
fechas <- fecha_ini + (1:plazo)
fechas
fechas <- fecha_ini + (0:plazo)
fechas
fechas <- fecha_ini + 0:(plazo-1)
fechas
beca <- fechas[format(fechas, "%d")=="01"]
beca
beca <- fechas[format(fechas, "%d")=="1"]
beca
beca <- fechas[format(fechas, "%d")=="01"]
beca
beca <- data.frame(dates=fechas[format(fechas, "%d")=="01"])
beca
beca$cantidad <- 1000
data$inc <- 1
beca$inc <- 1
beca$exp <- 0
beca$exp[data$inc==0] <- 1
View(beca)
beca$concepto <- "Aqui va un concepto"
View(beca)
beca <- data.frame(dates=fechas[format(fechas, "%d")==1])
beca
beca <- data.frame(dates=fechas[format(fechas, "%d")=="01"])
beca$cantidad <- 1000
recurrentes <- lis(beca=c(), banxico=c(), mesada=c())
recurrentes <- list(beca=c(), banxico=c(), mesada=c())
recurrentes
recurrentes <- list(beca=c(), banxico=c(), mesada=c())
beca <- list(cantidad=1000, fecha_ini=as.Date("01/01/2014", format = "%d/%m/%Y"), tipo=1)
banxico <- list(cantidad=1000, fecha_ini=as.Date("28/02/2014", format = "%d/%m/%Y"), tipo=1)
mesada <- list(cantidad=, fecha_ini=as.Date("05/01/2014", format = "%d/%m/%Y"), tipo=1)
mesada <- list(cantidad=500, fecha_ini=as.Date("05/01/2014", format = "%d/%m/%Y"), tipo=1)
recurrentes <- list(beca=beca, banxico=banxico, mesada=mesada)
recurrentes
library(datasets)
data(iris)
?iris
data(mtcars)
?mtcars
head(iris)
levels(iris$Species)
medias <- sapply(split(iris, iris$Species), function(x) colMeans(x[, colnames(iris)[1:4]]))
medias["Sepal.Length", "virginica"]
virginica <- split(iris, iris$Species)$virginica
mean(virginica$Sepal.Length)
mean(iris$Sepal.Length[iris$Species=="virginica"])
# ===== Question 2 =====
class(iris)
apply(iris, 2, mean) # Contiene la variable "Species"
apply(iris[, 1:4], 2, mean) # Solo contiene las variables numÃ©ricas
# ===== Question 3 =====
head(mtcars)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
# ===== Question 4 =====
medias_hp_cilindro <- sapply(split(mtcars$hp, mtcars$cyl), mean)
abs(medias_hp_cilindro[1] - medias_hp_cilindro[3])
?bin
?rbin
?rbin()
?rbinom
pbinom(12, 100, .1)
pbinom(12, 100, .1) - pbinom(10, 100, .1)
pbinom(22, 100, .1) - pbinom(20, 100, .1)
pbinom(22, 100, 2/10) - pbinom(20, 100, 2/10)
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
install.packages(c("boot", "class", "cluster", "codetools", "data.table", "httr", "jsonlite", "KernSmooth", "labeling", "maps", "MASS", "mgcv", "Rcpp", "RCurl", "spam", "swirl", "testthat", "xlsx", "xlsxjars"))
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = F)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "IN" | country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux_gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(httr)
require(httpuv)
require(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("quiz2", "041fe7d5df66f8834c1b", secret="85ab3505e732f175f8f4369367ee4db1abdbe4a6")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[5]]$name, output[[5]]$creat)
conexion <- url("http://biostat.jhsph.edu/~jleek/contact.html")
HTMLCode <- readLines(conexion)
close(conexion)
class(HTMLCode)
head(HTMLCode)
nchar(HTMLCode[10])
nchar(HTMLCode[20])
nchar(HTMLCode[30])
nchar(HTMLCode[100])
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
data_fwf <- read.fwf(file=con, skip=4, widths=c(11,8,4,9,4,9,4,9,4))
close(con)
sum(data_fwf[, 4])
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
library(dplyr)
cran <- tbl_df()
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package)
summarize(by_package, mean(size))
?n
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
??chain
submit()
submit()
submit()
submit()
dir_work <- "~/Desktop/repos/datasciencecoursera/Getting and Cleaning Data/assignment_2"
setwd(dir_work)
if(!file.exists("getdata-projectfiles-UCI HAR Dataset.zip")){
url_file <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url_file, "data.zip")
}
!file.exists("data.zip")
file.exists("data.zip")
download.file(url_file, "data.zip")
!file.exists("UCI HAR Dataset")
if(!file.exists("UCI HAR Dataset")){
unzip("data.zip")
}
# ========== Read the train data ==========
data_train <- read.table("./UCI HAR Dataset/train/x_train.txt")
label_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# ========== Read the test data ==========
data_test <- read.table("./UCI HAR Dataset/test/x_test.txt")
label_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# ========== Join the data ==========
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
label_joined <- rbind(label_train, label_test) # Join the train and test labels in one set
subject_joined <- rbind(subject_train, subject_test) # Join the train and test subjects in one set
# ========== Extracting the mean and std measurement ==========
features <- read.table("./UCI HAR Dataset/features.txt")
# Extract only features releated with mean or standard deviation
mean_index <- grep("mean\\(\\)|std\\(\\)", features[, 2])
# Keep only the features releated with mean or standard deviation
data_joined <- data_joined[, mean_index + 2]
# ========== Name the activities and subjects in the data set ==========
activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
label_joined <- tolower(activity[label_joined[, 1], 2])
subject_joined <- apply(subject_joined, 1, function(x) paste("Subject", x))
# ========== Merge the sets into an only tidy data set ==========
tidy_data <- cbind(subject_joined, label_joined, data_joined)
View(tidy_data)
head(tidy_data)
View(data_test)
features
grep("mean\\(\\)|std\\(\\)", features[, 2])
mean_index <- grep("mean\\(\\)|std\\(\\)", features[, 2])
data_joined <- data_joined[, mean_index]
mean_index
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
label_joined <- rbind(label_train, label_test) # Join the train and test labels in one set
subject_joined <- rbind(subject_train, subject_test) # Join the train and test subjects in one set
features <- read.table("./UCI HAR Dataset/features.txt")
mean_index <- grep("mean\\(\\)|std\\(\\)", features[, 2])
data_joined <- data_joined[, mean_index]
activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
label_joined <- tolower(activity[label_joined[, 1], 2])
subject_joined <- apply(subject_joined, 1, function(x) paste("Subject", x))
tidy_data <- cbind(subject_joined, label_joined, data_joined)
View(tidy_data)
raro <- read.table("./UCI HAR Dataset/train/x_train.txt/Inertial Signals/body_acc_x_train.txt")
raro <- read.table("./UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt")
View(raro)
View(tidy_data)
mean_index
features
features[mean_index, 2]
class(features[mean_index, 2])
names(tidy_data) <- c("Subject", "Activity", features[mean_index, 2])
View(tidy_data)
features[mean_index, 2]
c("Subject", "Activity", features[mean_index, 2])
features
features[, 2]
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
View(tidy_data)
names(tidy_data) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data) <- gsub("-", "", names(data_joined)) # remove "-" in column names
View(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
View(tidy_data)
names(tidy_data) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data) <- gsub("-", "", names(tidy_data)) # remove "-" in column names
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data)
names(tidy_data) <- gsub("\\(\\)", " ", features[mean_index, 2]) # remove "()"
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", " ", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)]) <- gsub("-", " ", names(tidy_data)) # remove "-" in column names
names(tidy_data)
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)]) <- gsub("-", "", names(tidy_data)) # remove "-" in column names
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data)
gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)])
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
gsub("-", "", names(tidy_data)) # remove "-" in column names
names(tidy_data[, -(1:2)]) <- gsub("-", "", names(tidy_data[, -(1:2)])) # remove "-" in column names
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)])
gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data)
gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
?gsub
names(tidy_data[, -(1:2)]) <- gsub("\\(\\)", "", features[mean_index, 2]) # remove "()"
names(tidy_data[, -(1:2)]) <- gsub("-", "", names(tidy_data[, -(1:2)])) # remove "-" in column names
names(tidy_data)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data)
gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("-", "", features[, 2]) # remove "-" in column names
features[, 2]
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", " ", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
features
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", " ", features[, 2]) # remove "()"
features[, 2] <- gsub("-", "", features[, 2]) # remove "-" in column names
features
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", " ", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
head(features)
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", " ", features[, 2]) # remove "()"
features
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
head(features) <- read.table("./UCI HAR Dataset/features.txt")
head(features)
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
tidy_data <- c("Subject", "Activity", as.character(features[mean_index, 2]))
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
head(tidy_data)
dir_work <- "~/Desktop/repos/datasciencecoursera/Getting and Cleaning Data/assignment_2"
setwd(dir_work)
# Download the da, if the data isn't already downloaded in the workspace.
if(!file.exists("data.zip")){
url_file <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url_file, "data.zip")
}
# Unzip the data if the data isn't already unziped
if(!file.exists("UCI HAR Dataset")){
unzip("data.zip")
}
raro <- read.table("./UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt")
# ========== Read the train data ==========
data_train <- read.table("./UCI HAR Dataset/train/x_train.txt")
label_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# ========== Read the test data ==========
data_test <- read.table("./UCI HAR Dataset/test/x_test.txt")
label_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# ========== Join the data ==========
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
label_joined <- rbind(label_train, label_test) # Join the train and test labels in one set
subject_joined <- rbind(subject_train, subject_test) # Join the train and test subjects in one set
# ========== Extracting the mean and std measurement ==========
# Load the features from the file and make it readable
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
# Extract only features releated with mean or standard deviation
mean_index <- grep("mean\\(\\) | std\\(\\)", features[, 2])
# Keep only the features releated with mean or standard deviation
data_joined <- data_joined[, mean_index]
# ========== Name the activities and subjects in the data set ==========
activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
label_joined <- tolower(activity[label_joined[, 1], 2])
subject_joined <- apply(subject_joined, 1, function(x) paste("Subject", x))
# ========== Merge the sets into an only tidy data set ==========
tidy_data <- cbind(subject_joined, label_joined, data_joined)
# ========== Name the variables with descriptive names ==========
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
head(tidy_data)
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
mean_index <- grep("mean\\(\\) | std\\(\\)", features[, 2])
mean_index
mean_index <- grep("mean | std", features[, 2])
mean_index
# Set the working directory in the place where you're going to work
dir_work <- "~/Desktop/repos/datasciencecoursera/Getting and Cleaning Data/assignment_2"
setwd(dir_work)
# Download the da, if the data isn't already downloaded in the workspace.
if(!file.exists("data.zip")){
url_file <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url_file, "data.zip")
}
# Unzip the data if the data isn't already unziped
if(!file.exists("UCI HAR Dataset")){
unzip("data.zip")
}
# ========== Read the train data ==========
data_train <- read.table("./UCI HAR Dataset/train/x_train.txt")
label_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
# ========== Read the test data ==========
data_test <- read.table("./UCI HAR Dataset/test/x_test.txt")
label_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# ========== Join the data ==========
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
label_joined <- rbind(label_train, label_test) # Join the train and test labels in one set
subject_joined <- rbind(subject_train, subject_test) # Join the train and test subjects in one set
# ========== Extracting the mean and std measurement ==========
# Load the features from the file and make it readable
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
# Extract only features releated with mean or standard deviation
mean_index <- grep("mean | std", features[, 2])
# Keep only the features releated with mean or standard deviation
data_joined <- data_joined[, mean_index]
# ========== Name the activities and subjects in the data set ==========
activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
label_joined <- tolower(activity[label_joined[, 1], 2])
subject_joined <- apply(subject_joined, 1, function(x) paste("Subject", x))
# ========== Merge the sets into an only tidy data set ==========
tidy_data <- cbind(subject_joined, label_joined, data_joined)
# ========== Name the variables with descriptive names ==========
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
head(tidy_data)
new_data <- tidy_data
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
# library(dplyr)
library(dplyr)
install.packages(dplyr)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
require(dplyr)
head(new_data)
new_data <- select(new_data, Subject, Activity)
head(new_data)
new_data <- tidy_data
new_data <- arrange(new_data, Subject, Activity)
head(new_data)
View(new_data)
new_data <- arrange(new_data, as.number(Subject), Activity)
new_data <- arrange(new_data, as.numeric(Subject), Activity)
View(new_data)
# Set the working directory in the place where you're going to work
dir_work <- "~/Desktop/repos/datasciencecoursera/Getting and Cleaning Data/assignment_2"
setwd(dir_work)
require(dplyr)
# ========== Download the data ==========
if(!file.exists("data.zip")){
url_file <- "http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url_file, "data.zip")
}
# Unzip the data if the data isn't already unziped
if(!file.exists("UCI HAR Dataset")){
unzip("data.zip")
}
# ========== Read the data ==========
data_train <- read.table("./UCI HAR Dataset/train/x_train.txt")
label_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
data_test <- read.table("./UCI HAR Dataset/test/x_test.txt")
label_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
# ========== 1 Merge the data ==========
data_joined <- rbind(data_train, data_test) # Join the train and test data in one set
label_joined <- rbind(label_train, label_test) # Join the train and test labels in one set
subject_joined <- rbind(subject_train, subject_test) # Join the train and test subjects in one set
# ========== 2 Extracting the mean and std measurements ==========
# Load the features from the file and make it readable
features <- read.table("./UCI HAR Dataset/features.txt")
features[, 2] <- gsub("\\(\\)", "", features[, 2]) # remove "()"
features[, 2] <- gsub("-", " ", features[, 2]) # remove "-" in column names
# Extract only features releated with mean or standard deviation
mean_index <- grep("mean | std", features[, 2])
# Keep only the features releated with mean or standard deviation
data_joined <- data_joined[, mean_index]
# ========== 3 Name the activities and subjects in the data set ==========
activity <- read.table("./UCI HAR Dataset/activity_labels.txt")
label_joined <- tolower(activity[label_joined[, 1], 2])
# Merge the sets into an only tidy data set
tidy_data <- cbind(subject_joined, label_joined, data_joined)
tidy_data <- arrange(tidy_data, Subject, Activity)
# Name the variables with descriptive names
names(tidy_data) <- c("Subject", "Activity", as.character(features[mean_index, 2]))
tidy_data$Subject <- apply(tidy_data$Subject, 1, function(x) paste("Subject", x))
# ========== 4 Write the text file ==========
write.table(tidy_data, "tidy_data.txt")
# ========== Create a new set of data ==========
new_data <- tidy_data
View(tidy_data)
unique(tidy_data$Subject)
tidy_data <- arrange(tidy_data, Subject, Activity)
unique(tidy_data$Subject)
tidy_data$Subject <- apply(tidy_data$Subject, 1, function(x) paste("Subject", x))
tidy_data[, 1] <- apply(tidy_data[,1], 1, function(x) paste("Subject", x))
